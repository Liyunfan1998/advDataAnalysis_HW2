{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding:utf-8 -*-\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "# cifa = input_data.read_data_sets(\"../cifar_10\", one_hot=True)\n",
    "data_dir = '/Users/liyunfan/targetDirectory/cifar_10/cifar-10-batches-py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_CIFAR_batch(filename):\n",
    "  \"\"\" load single batch of cifar \"\"\"\n",
    "  with open(filename, 'rb') as f:\n",
    "    datadict = pickle.load(f)\n",
    "    X = datadict['data']\n",
    "    Y = datadict['labels']\n",
    "    X = X.reshape(10000, 3, 32,32).transpose(0,2,3,1).astype(\"float\")\n",
    "    Y = np.array(Y)\n",
    "    return X, Y\n",
    "def load_CIFAR10(ROOT):\n",
    "  \"\"\" load all of cifar \"\"\"\n",
    "  xs = []\n",
    "  ys = []\n",
    "  for b in range(1,6):\n",
    "    f = os.path.join(ROOT, 'data_batch_%d' % (b, ))\n",
    "    X, Y = load_CIFAR_batch(f)\n",
    "    xs.append(X)\n",
    "    ys.append(Y)\n",
    "  Xtr = np.concatenate(xs)#使变成行向量\n",
    "  Ytr = np.concatenate(ys)\n",
    "  del X, Y\n",
    "  Xte, Yte = load_CIFAR_batch(os.path.join(ROOT, 'test_batch'))\n",
    "  return Xtr, Ytr, Xte, Yte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(batch_size, image, label):\n",
    "    batch_image = list()\n",
    "    batch_label = list()\n",
    "    indexs = list()\n",
    "    for i in range(batch_size):\n",
    "        index = random.randint(0, len(image) - 1)\n",
    "        while index in indexs:\n",
    "            index = random.randint(0, len(image) - 1)\n",
    "        d = list(image[index])\n",
    "        batch_image.append(d)\n",
    "        z = label[index]\n",
    "        batch_label.append(z)\n",
    "        indexs.append(index)\n",
    "    return batch_image, batch_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, pickle\n",
    "# sys.path.append(\"..\")\n",
    "# sys.path.append(\"./tutorials/\")\n",
    "batch_size = 128\n",
    "XtrAll, YtrAll, XteAll, YteAll = load_CIFAR10(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YtrAll.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneHotY(Y):\n",
    "    Y_new=np.array([[0]*10]*len(Y))\n",
    "    for i in range(len(Y)):\n",
    "        Y_new[i][Y[i]]=1\n",
    "    return Y_new\n",
    "\n",
    "# YtrAll = oneHotY(YtrAll)\n",
    "# YteAll = oneHotY(YteAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape, stddev=5e-2, wl=0):#w1是L1正则中的系数\n",
    "    var = tf.Variable(tf.truncated_normal(shape, stddev=stddev))\n",
    "    if wl is not None:\n",
    "        # 给weight加一个L2的loss，相当于做了一个L2的正则化处理\n",
    "        weight_loss = tf.multiply(tf.nn.l2_loss(var), wl, name='weight_loss')\n",
    "        # 我们使用tf.add_to_collection把weight loss统一存到一个collection，这个collection名为\"losses\"\n",
    "        # 它会在后面计算神经网络总体loss时被用上\n",
    "        tf.add_to_collection(\"losses\", weight_loss)\n",
    "    return var\n",
    "\"\"\"\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\"\"\"\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "# 卷积函数的四个参数分别是训练图像，卷积核，步长，填充\n",
    "def conv2d(x, W):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "# 求最大值池化，长宽缩小一半\n",
    "def max_pool_2x2(x):\n",
    "  return tf.nn.max_pool(x, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_layer(inputs, w_shape, b_shape, activation_function=None,mul_func = tf.matmul,pool=None,wl=0,stddev=5e-2,norm=False):\n",
    "#     Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "#     biases = tf.Variable(tf.zeros([1, out_size]))\n",
    "    Weights = weight_variable(w_shape,stddev=5e-2,wl=wl)\n",
    "    biases = bias_variable(b_shape)\n",
    "    Wx_plus_b = mul_func(inputs, Weights)+biases\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    if norm:\n",
    "        outputs= tf.nn.lrn(outputs, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)\n",
    "    if pool is not None:\n",
    "        outputs = pool(outputs)\n",
    "        \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(logits, labels):\n",
    "    labels = tf.cast(labels, tf.int64)#真实标签0-9\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "        logits=logits, labels=labels, name='cross_entropy_per_example'\n",
    "    )#交叉熵\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy,\n",
    "                                        name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)#加到最开始定义的集合这里最后又两部分交叉熵损失函数+L2损失函数\n",
    "\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')#拿到两部分损失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "# x = tf.placeholder('float', shape=[batch_size, 32, 32, 3])\n",
    "# y_ = tf.placeholder('float', shape=[batch_size])\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, 32,32,3])\n",
    "y_ = tf.placeholder(tf.float32, [None])\n",
    "\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_shape1=[3,3,3,64]\n",
    "b_shape1=[64]\n",
    "\n",
    "x_image = tf.reshape(x,[-1, 32,32,3])\n",
    "out1 = add_layer(x_image,w_shape=w_shape1,\n",
    "                 b_shape=b_shape1,mul_func=conv2d,\n",
    "                 activation_function=tf.nn.relu, pool=max_pool_2x2)\n",
    "norm1 = tf.nn.lrn(out1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "w_shape2=[3,3,64,64]\n",
    "b_shape2=[64]\n",
    "\n",
    "out2 = add_layer(out1,w_shape=w_shape2,\n",
    "                 b_shape=b_shape2,mul_func=conv2d,\n",
    "                 activation_function=tf.nn.relu, pool=max_pool_2x2,norm=True)\n",
    "\n",
    "out2_flat=tf.reshape(out2,[batch_size,-1]) # flatten\n",
    "ofdim = out2_flat.get_shape()[1].value\n",
    "print ofdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_shape3=[8* 8 * 64,1024]\n",
    "b_shape3=[1024]\n",
    "\n",
    "# out2_flat = tf.reshape(out2,[-1,ofdim])\n",
    "out3 = add_layer(out2_flat,w_shape=w_shape3,\n",
    "                 b_shape=b_shape3,\n",
    "                 activation_function=tf.nn.relu,stddev=0.04, wl=0.004)\n",
    "\n",
    "# 随机关闭一些神经元防止过拟\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "out3 = tf.nn.dropout(out3, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_shape4 =[1024, 512]\n",
    "b_shape4 = [512]\n",
    "\n",
    "out4 = add_layer(out3,w_shape4,b_shape4,activation_function=tf.nn.relu, stddev=0.04, wl=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(10)])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 从1024个神经元映射到10个神经元\n",
    "w_shape5 =[512, 10]\n",
    "b_shape5 = [10]\n",
    "\n",
    "pred = add_layer(out4,w_shape5,b_shape5,tf.nn.softmax, stddev=1/512.0)\n",
    "\n",
    "pred.shape\n",
    "# labels = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
    "# b=tf.cast(labels, tf.int64)\n",
    "# sess = tf.Session()\n",
    "# sess.run(tf.initialize_all_variables())\n",
    "# print(sess.run(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(100), Dimension(10)])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_=tf.cast(y_,tf.int32)\n",
    "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=out4, labels=y_)\n",
    "cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "tf.add_to_collection('losses', cross_entropy_mean)\n",
    "loss = tf.add_n(tf.get_collection('losses'), name='total_loss')\n",
    "tf.summary.scalar('losses',loss)\n",
    "\n",
    "# train_op = tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
    "Xte = tf.placeholder(tf.float32, [None, 32,32,3])\n",
    "Yte = tf.placeholder(tf.int32, [None])\n",
    "# top_k_op = tf.nn.in_top_k(Xte, Yte, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算交叉熵损失\n",
    "# cross_entropy = -tf.reduce_sum(y_*tf.log(pred))\n",
    "# # 创建优化器\n",
    "# train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "# 计算准确率， tf.argmax函数 在 label 中找出数值最大的那个元素的下标\n",
    "# correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\n",
    "# accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "top_k_op = tf.nn.in_top_k(out4, y_, 1)\n",
    "sess.run(tf.global_variables_initializer())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"summary_op =  tf.summary.merge_all()\\nsess.run(tf.global_variables_initializer())\\nfor step in range(max_steps):\\n    start_time = time.time()\\n    image_batch, label_batch = get_batch(batch_size=batch_size,image=XtrAll,label=YtrAll)\\n    image_batch= np.array(image_batch)\\n    label_batch=1.0*np.array(label_batch)\\n    print image_batch.dtype, label_batch.shape\\n    \\n#     image_batch, label_batch = sess.run([images_train, labels_train])#\\xe7\\x9c\\x9f\\xe6\\xad\\xa3\\xe6\\x89\\xa7\\xe8\\xa1\\x8ctensor\\xe9\\x80\\xbb\\xe8\\xbe\\x91 \\xe8\\xbf\\x94\\xe5\\x9b\\x9e\\xe7\\x9a\\x84\\xe6\\x98\\xaf\\xe4\\xb8\\x80\\xe6\\x89\\xb9\\xe6\\xac\\xa1\\xe7\\x9a\\x84\\xe6\\x95\\xb0\\xe6\\x8d\\xae\\n    _, loss_value,summary_str = sess.run([train_op, loss,summary_op],feed_dict={x: image_batch, y_: label_batch})\\n    duration = time.time() - start_time\\n    if step % 10 == 0:\\n        examples_per_sec = batch_size / duration\\n        sec_per_batch = float(duration)\\n\\n        format_str = 'step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)'\\n        print(format_str % (step, loss_value, examples_per_sec, sec_per_batch))\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import time\n",
    "# tf.train.start_queue_runners()\n",
    "\"\"\"summary_op =  tf.summary.merge_all()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "for step in range(max_steps):\n",
    "    start_time = time.time()\n",
    "    image_batch, label_batch = get_batch(batch_size=batch_size,image=XtrAll,label=YtrAll)\n",
    "    image_batch= np.array(image_batch)\n",
    "    label_batch=1.0*np.array(label_batch)\n",
    "    print image_batch.dtype, label_batch.shape\n",
    "    \n",
    "#     image_batch, label_batch = sess.run([images_train, labels_train])#真正执行tensor逻辑 返回的是一批次的数据\n",
    "    _, loss_value,summary_str = sess.run([train_op, loss,summary_op],feed_dict={x: image_batch, y_: label_batch})\n",
    "    duration = time.time() - start_time\n",
    "    if step % 10 == 0:\n",
    "        examples_per_sec = batch_size / duration\n",
    "        sec_per_batch = float(duration)\n",
    "\n",
    "        format_str = 'step %d, loss = %.2f (%.1f examples/sec; %.3f sec/batch)'\n",
    "        print(format_str % (step, loss_value, examples_per_sec, sec_per_batch))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"def next_batch(datasetX,datasetY,batch_size,nowAt):\n",
    "    return datasetX[nowAt:nowAt+batch_size],datasetY[nowAt:nowAt+batch_size],nowAt+batch_size\"\"\"pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"for i in range(20000):\n",
    "    nowAt=0\n",
    "#     print nowAt\n",
    "    Xtr,Ytr,a = next_batch(XtrAll,YtrAll,batch_size,nowAt)\n",
    "    Xte,Yte,nowAt = next_batch(XteAll,YteAll,batch_size,nowAt)\n",
    "    if (i%100 == 0):\n",
    "        train_accuracy = accuracy.eval(feed_dict={\n",
    "        x:Xtr, y_: Ytr, keep_prob: 1.0})\n",
    "        print (\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "      # 运行训练模型\n",
    "    train_step.run(feed_dict={x: Xtr, y_: Ytr, keep_prob: 0.5})\n",
    "print (\"test accuracy %g\"%accuracy.eval(feed_dict={\n",
    "x: Xte, y_: Yte, keep_prob: 1.0}))\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess=tf.InteractiveSession()\n",
    "# sess.run(tf.global_variables_initializer())\n",
    "\n",
    "#保存模型\n",
    "saver = tf.train.Saver()\n",
    "saveFile='./CNNmodles/cifar10/CNN_cifar10.ckpt'\n",
    "\n",
    "# 使用tensorboard ，保存至LOG文件夹\n",
    "merged = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter('./LOG2' , sess.graph)\n",
    "import random\n",
    "test_a=list()\n",
    "epoch_num=41\n",
    "n_batch = 50000 // batch_size\n",
    "#epoch：迭代次数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [100,32,32,3]\n\t [[node Placeholder (defined at <ipython-input-10-3a49e7393409>:5) ]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/usr/local/Cellar/python@2/2.7.15_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python@2/2.7.15_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/ioloop.py\", line 1017, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 542, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-3a49e7393409>\", line 5, in <module>\n    x = tf.placeholder(tf.float32, [batch_size, 32,32,3])\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [100,32,32,3]\n\t [[node Placeholder (defined at <ipython-input-10-3a49e7393409>:5) ]]\n",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-0816b621044f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mbatch_images\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mbatch_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcross_entropy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx_image\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbatch_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"epoch:\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\" batch:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cross_entropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [100,32,32,3]\n\t [[node Placeholder (defined at <ipython-input-10-3a49e7393409>:5) ]]\n\nCaused by op u'Placeholder', defined at:\n  File \"/usr/local/Cellar/python@2/2.7.15_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 174, in _run_module_as_main\n    \"__main__\", fname, loader, pkg_name)\n  File \"/usr/local/Cellar/python@2/2.7.15_3/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py\", line 72, in _run_code\n    exec code in run_globals\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelapp.py\", line 499, in start\n    self.io_loop.start()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/ioloop.py\", line 1017, in start\n    self._run_callback(self._callbacks.popleft())\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/ioloop.py\", line 758, in _run_callback\n    ret = callback()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 542, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 456, in _handle_events\n    self._handle_recv()\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 486, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/zmq/eventloop/zmqstream.py\", line 438, in _run_callback\n    callback(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tornado/stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-10-3a49e7393409>\", line 5, in <module>\n    x = tf.placeholder(tf.float32, [batch_size, 32,32,3])\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/ops/array_ops.py\", line 2077, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 5791, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/op_def_library.py\", line 788, in _apply_op_helper\n    op_def=op_def)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/util/deprecation.py\", line 507, in new_func\n    return func(*args, **kwargs)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 3300, in create_op\n    op_def=op_def)\n  File \"/Users/liyunfan/targetDirectory/lib/python2.7/site-packages/tensorflow/python/framework/ops.py\", line 1801, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder' with dtype float and shape [100,32,32,3]\n\t [[node Placeholder (defined at <ipython-input-10-3a49e7393409>:5) ]]\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "for epoch in range(epoch_num):\n",
    "    for batch in range(n_batch):\n",
    "        #batch_ys_onehot = np.eye(10, dtype=float)[batch_labels]\n",
    "        batch_images, batch_labels = get_batch(batch_size,  XtrAll,YtrAll)\n",
    "        batch_images=np.array(batch_images,dtype=np.float)\n",
    "        batch_labels=np.array(label_batch,dtype=np.float)\n",
    "        _, cross_entropy = sess.run([train_op, loss], feed_dict={x_image: batch_images, y_: batch_labels, keep_prob: 1})\n",
    "        if batch % 100 == 0:\n",
    "            print(\"epoch:\" ,str(epoch) ,\" batch:\",batch,'cross_entropy',cross_entropy)\n",
    "#         train_writer.add_summary(summary, epoch*50000+batch)\n",
    "\n",
    "    #每个epoch后，计算训练出的模型在测试集上的准确率\n",
    "    accuracy = sess.run([top_k_op], feed_dict={x_image: XteAll, y_: YteAll, keep_prob: 1})\n",
    "    test_accuracy = float(np.sum(accuracy) / 10000)\n",
    "    test_a.append(test_accuracy)\n",
    "    print(\"epoch:%d  test accuracy %f\" % (epoch, test_accuracy))\n",
    "train_writer.close()\n",
    "saver.save(sess, saveFile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[142., 147., 180.],\n",
       "         [146., 151., 179.],\n",
       "         [144., 145., 167.],\n",
       "         ...,\n",
       "         [147., 155., 178.],\n",
       "         [147., 155., 177.],\n",
       "         [142., 149., 172.]],\n",
       "\n",
       "        [[142., 144., 180.],\n",
       "         [150., 148., 174.],\n",
       "         [125., 118., 132.],\n",
       "         ...,\n",
       "         [140., 150., 173.],\n",
       "         [140., 150., 173.],\n",
       "         [136., 144., 168.]],\n",
       "\n",
       "        [[143., 143., 175.],\n",
       "         [151., 142., 161.],\n",
       "         [123., 106., 113.],\n",
       "         ...,\n",
       "         [136., 149., 174.],\n",
       "         [137., 149., 175.],\n",
       "         [133., 144., 169.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[100.,  81.,  64.],\n",
       "         [119.,  94.,  75.],\n",
       "         [122.,  93.,  73.],\n",
       "         ...,\n",
       "         [112.,  98.,  72.],\n",
       "         [104.,  86.,  64.],\n",
       "         [ 97.,  79.,  62.]],\n",
       "\n",
       "        [[112.,  92.,  70.],\n",
       "         [120.,  95.,  74.],\n",
       "         [125.,  92.,  73.],\n",
       "         ...,\n",
       "         [124.,  99.,  77.],\n",
       "         [116.,  90.,  69.],\n",
       "         [107.,  83.,  66.]],\n",
       "\n",
       "        [[117., 100.,  73.],\n",
       "         [120., 102.,  77.],\n",
       "         [127.,  96.,  76.],\n",
       "         ...,\n",
       "         [116.,  98.,  75.],\n",
       "         [127., 107.,  83.],\n",
       "         [121.,  98.,  77.]]],\n",
       "\n",
       "\n",
       "       [[[253., 253., 253.],\n",
       "         [250., 251., 251.],\n",
       "         [250., 251., 250.],\n",
       "         ...,\n",
       "         [250., 251., 251.],\n",
       "         [249., 252., 251.],\n",
       "         [251., 252., 251.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [255., 254., 254.],\n",
       "         [255., 254., 254.],\n",
       "         ...,\n",
       "         [252., 254., 255.],\n",
       "         [251., 255., 255.],\n",
       "         [254., 255., 255.]],\n",
       "\n",
       "        [[254., 255., 255.],\n",
       "         [253., 251., 252.],\n",
       "         [248., 245., 246.],\n",
       "         ...,\n",
       "         [241., 243., 242.],\n",
       "         [247., 249., 248.],\n",
       "         [252., 253., 253.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [253., 251., 251.],\n",
       "         [226., 223., 215.],\n",
       "         ...,\n",
       "         [108., 103.,  96.],\n",
       "         [107., 101., 104.],\n",
       "         [142., 139., 142.]],\n",
       "\n",
       "        [[255., 255., 255.],\n",
       "         [253., 252., 253.],\n",
       "         [243., 241., 240.],\n",
       "         ...,\n",
       "         [100.,  98.,  95.],\n",
       "         [116., 113., 118.],\n",
       "         [156., 155., 157.]],\n",
       "\n",
       "        [[255., 254., 255.],\n",
       "         [252., 252., 253.],\n",
       "         [244., 244., 244.],\n",
       "         ...,\n",
       "         [136., 137., 136.],\n",
       "         [148., 148., 151.],\n",
       "         [179., 179., 181.]]],\n",
       "\n",
       "\n",
       "       [[[125., 174., 180.],\n",
       "         [124., 172., 180.],\n",
       "         [126., 174., 179.],\n",
       "         ...,\n",
       "         [ 54.,  59.,  58.],\n",
       "         [ 49.,  52.,  55.],\n",
       "         [ 44.,  47.,  50.]],\n",
       "\n",
       "        [[143., 186., 195.],\n",
       "         [143., 185., 193.],\n",
       "         [142., 186., 191.],\n",
       "         ...,\n",
       "         [ 92., 105.,  92.],\n",
       "         [ 75.,  87.,  72.],\n",
       "         [ 64.,  76.,  62.]],\n",
       "\n",
       "        [[160., 196., 207.],\n",
       "         [157., 195., 202.],\n",
       "         [160., 197., 203.],\n",
       "         ...,\n",
       "         [112., 131., 121.],\n",
       "         [ 95., 113.,  96.],\n",
       "         [ 91., 109.,  90.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[122., 118., 115.],\n",
       "         [106., 102.,  99.],\n",
       "         [ 90.,  86.,  84.],\n",
       "         ...,\n",
       "         [159., 158., 157.],\n",
       "         [156., 132., 133.],\n",
       "         [136., 117., 101.]],\n",
       "\n",
       "        [[152., 147., 141.],\n",
       "         [133., 128., 124.],\n",
       "         [116., 111., 106.],\n",
       "         ...,\n",
       "         [122., 117., 105.],\n",
       "         [131., 124., 100.],\n",
       "         [125., 119.,  84.]],\n",
       "\n",
       "        [[199., 193., 175.],\n",
       "         [173., 166., 155.],\n",
       "         [150., 144., 133.],\n",
       "         ...,\n",
       "         [109., 107.,  66.],\n",
       "         [110., 111.,  62.],\n",
       "         [107., 108.,  61.]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[ 47.,  78., 173.],\n",
       "         [ 43.,  80., 183.],\n",
       "         [ 44.,  82., 176.],\n",
       "         ...,\n",
       "         [ 25.,  34., 126.],\n",
       "         [ 19.,  35., 125.],\n",
       "         [ 23.,  38., 105.]],\n",
       "\n",
       "        [[ 45.,  80., 196.],\n",
       "         [ 41.,  81., 206.],\n",
       "         [ 39.,  81., 197.],\n",
       "         ...,\n",
       "         [ 18.,  34., 147.],\n",
       "         [ 11.,  33., 145.],\n",
       "         [ 14.,  34., 118.]],\n",
       "\n",
       "        [[ 44.,  83., 205.],\n",
       "         [ 40.,  84., 214.],\n",
       "         [ 41.,  86., 208.],\n",
       "         ...,\n",
       "         [ 18.,  42., 161.],\n",
       "         [ 11.,  40., 158.],\n",
       "         [ 12.,  38., 125.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[143., 133., 140.],\n",
       "         [195., 179., 192.],\n",
       "         [196., 175., 196.],\n",
       "         ...,\n",
       "         [ 17.,  14.,  39.],\n",
       "         [ 17.,  18.,  45.],\n",
       "         [ 17.,  19.,  38.]],\n",
       "\n",
       "        [[145., 140., 144.],\n",
       "         [206., 193., 206.],\n",
       "         [126., 105., 127.],\n",
       "         ...,\n",
       "         [ 12.,  12.,  33.],\n",
       "         [ 11.,  11.,  38.],\n",
       "         [ 10.,  11.,  30.]],\n",
       "\n",
       "        [[105., 107., 101.],\n",
       "         [138., 133., 135.],\n",
       "         [ 95.,  82.,  93.],\n",
       "         ...,\n",
       "         [ 51.,  52.,  59.],\n",
       "         [ 48.,  48.,  62.],\n",
       "         [ 47.,  48.,  59.]]],\n",
       "\n",
       "\n",
       "       [[[ 81.,  43.,  24.],\n",
       "         [156.,  93.,  54.],\n",
       "         [ 69.,  44.,  31.],\n",
       "         ...,\n",
       "         [116.,  78.,  52.],\n",
       "         [ 84.,  92.,  95.],\n",
       "         [ 84.,  95.,  99.]],\n",
       "\n",
       "        [[ 68.,  32.,  17.],\n",
       "         [143.,  85.,  52.],\n",
       "         [ 52.,  31.,  23.],\n",
       "         ...,\n",
       "         [106.,  79.,  60.],\n",
       "         [ 85.,  94.,  97.],\n",
       "         [ 83.,  94.,  98.]],\n",
       "\n",
       "        [[ 71.,  35.,  20.],\n",
       "         [144.,  88.,  56.],\n",
       "         [ 51.,  32.,  26.],\n",
       "         ...,\n",
       "         [ 99.,  86.,  74.],\n",
       "         [ 88.,  97., 101.],\n",
       "         [ 84.,  94.,  99.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[116., 117., 121.],\n",
       "         [110., 121., 120.],\n",
       "         [131., 130., 134.],\n",
       "         ...,\n",
       "         [ 25.,  29.,  30.],\n",
       "         [ 20.,  23.,  23.],\n",
       "         [ 20.,  22.,  21.]],\n",
       "\n",
       "        [[121., 123., 124.],\n",
       "         [127., 134., 131.],\n",
       "         [140., 131., 136.],\n",
       "         ...,\n",
       "         [ 49.,  52.,  53.],\n",
       "         [ 22.,  24.,  26.],\n",
       "         [ 23.,  24.,  26.]],\n",
       "\n",
       "        [[126., 126., 124.],\n",
       "         [134., 137., 134.],\n",
       "         [153., 140., 144.],\n",
       "         ...,\n",
       "         [ 76.,  78.,  79.],\n",
       "         [ 38.,  40.,  42.],\n",
       "         [ 29.,  30.,  33.]]],\n",
       "\n",
       "\n",
       "       [[[104., 121., 167.],\n",
       "         [103., 119., 165.],\n",
       "         [102., 119., 165.],\n",
       "         ...,\n",
       "         [125., 137., 173.],\n",
       "         [122., 135., 171.],\n",
       "         [122., 134., 170.]],\n",
       "\n",
       "        [[105., 123., 169.],\n",
       "         [104., 121., 167.],\n",
       "         [104., 121., 167.],\n",
       "         ...,\n",
       "         [120., 132., 173.],\n",
       "         [117., 129., 170.],\n",
       "         [118., 130., 171.]],\n",
       "\n",
       "        [[106., 123., 169.],\n",
       "         [105., 122., 168.],\n",
       "         [105., 122., 168.],\n",
       "         ...,\n",
       "         [123., 134., 178.],\n",
       "         [122., 133., 177.],\n",
       "         [118., 129., 174.]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[125., 139., 178.],\n",
       "         [131., 145., 182.],\n",
       "         [134., 149., 183.],\n",
       "         ...,\n",
       "         [150., 159., 188.],\n",
       "         [147., 156., 185.],\n",
       "         [146., 155., 184.]],\n",
       "\n",
       "        [[125., 138., 178.],\n",
       "         [130., 144., 181.],\n",
       "         [131., 145., 179.],\n",
       "         ...,\n",
       "         [153., 162., 191.],\n",
       "         [147., 156., 185.],\n",
       "         [143., 152., 181.]],\n",
       "\n",
       "        [[123., 137., 178.],\n",
       "         [127., 141., 179.],\n",
       "         [129., 143., 180.],\n",
       "         ...,\n",
       "         [157., 165., 190.],\n",
       "         [153., 161., 186.],\n",
       "         [149., 157., 181.]]]], dtype=float32)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 32, 32, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ndarray([100, 32, 32, 3]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
